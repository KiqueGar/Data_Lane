{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from evaluate.lane import LaneEval\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D, Dense, Flatten\n",
    "from keras.layers import Deconvolution2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load trainig images\n",
    "pickle_data = pickle.load(open(\"GT_images.p\", \"rb\" ))\n",
    "train_images = pickle_data[\"GroundTruth\"]\n",
    "\n",
    "#Load Polinomials\n",
    "pickle_data = pickle.load(open(\"polynomials.p\", \"rb\" ))\n",
    "labels = pickle_data[\"Polynomials\"]\n",
    "plt.imshow(train_images[70])\n",
    "plt.show()\n",
    "\n",
    "new_labels = []\n",
    "for i in range(len(train_images)):\n",
    "    train_images[i]=np.float32(train_images[i][:,:,:3])\n",
    "    mask = train_images[i][:,:,1]\n",
    "    train_images[i]=mask\n",
    "    \n",
    "    coeffs=np.ndarray.tolist(np.concatenate(np.asarray(labels[i])))\n",
    "    #Five lanes included, triming :/ this could be done better\n",
    "    if(len(coeffs)>12):\n",
    "        coeffs=coeffs[:12]\n",
    "    new_labels.append(coeffs)\n",
    "    \n",
    "\n",
    "train_images=np.float32(train_images).reshape((-1,80,160,1))\n",
    "new_labels=np.asarray(new_labels)\n",
    "labels=[]\n",
    "print(\"Training data Loaded\")\n",
    "print(train_images.shape,new_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Scaler for polynomial coeffs\n",
    "Y_scaler=StandardScaler().fit(new_labels)\n",
    "Y_scaled=Y_scaler.transform(new_labels)\n",
    "#Image normalization\n",
    "X=train_images/255\n",
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "X, Y_scaled = shuffle(X, Y_scaled)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y_scaled, test_size=0.15)\n",
    "\n",
    "print(\"Training on: \", len(X_train), \" samples\")\n",
    "print(\"Training on: \", len(X_val), \" samples\")\n",
    "\n",
    "print(Y_scaled[0])\n",
    "\n",
    "scaler_file= 'Y_scaler.sav'\n",
    "pickle.dump(Y_scaler, open(scaler_file, 'wb'))\n",
    "print(\"Scaler Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels=[]\n",
    "train_images=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "epochs = 50\n",
    "pool_size = (2, 2)\n",
    "input_shape = X.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# Below layers were re-named for easier reading of model summary; this not necessary\n",
    "# Conv Layer 1\n",
    "model.add(Convolution2D(2, 3, 3, border_mode='valid', subsample=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "# Conv Layer 2\n",
    "#model.add(Convolution2D(3, 3, 3, border_mode='valid', subsample=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "# Pooling 1\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation= 'elu'))\n",
    "model.add(Dense(12, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Feeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss='mean_absolute_percentage_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), samples_per_epoch = len(X_train),\n",
    "                    nb_epoch=epochs, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save model architecture and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"lanes_CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('lanes_CNN_model.h5')\n",
    "\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
